{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# output metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_metric = {\n",
    "                \"Total CO2e Emissions\":\n",
    "                    [\"Emissions?\"],\n",
    "                \"CO2e Emissions, Scope 1\":\n",
    "                    [\"Emissions?\", \"Scope 1\"],\n",
    "                \"CO2e Emissions, Scope 2\":\n",
    "                    [\"Emissions?\", \"Scope 2\"],\n",
    "                \"CO2e Emissions, Scope 3\":\n",
    "                    [\"Emissions?\", \"Scope 3\"],\n",
    "                \"Emissions Policy\":\n",
    "                    [\"Emissions?\"],\n",
    "                \"Emission Reduction Target %\":\n",
    "                    [\"Emissions?\"],\n",
    "                \"Emissions Reduction Target Year\":\n",
    "                    [\"Emissions?\"],\n",
    "                \"Total Water Withdrawal\":\n",
    "                    [\"Water\"],\n",
    "                \"Water Discharged\":\n",
    "                    [\"Water\"],\n",
    "                \"Total Fresh Water Withdrawal\":\n",
    "                    [\"Water\"],\n",
    "                \"Water Recycled\":\n",
    "                    [\"Water\"],\n",
    "                \"Water Efficiency Target\":\n",
    "                    [\"Water\"],\n",
    "                \"Total Energy Consumed\":\n",
    "                    [\"Energy\"],\n",
    "                \"Total Renewable Energy\":\n",
    "                    [\"Energy\"],\n",
    "                \"Renewable Energy Consumed\":\n",
    "                    [\"Energy\"],\n",
    "                \"Renewable Energy Use\":\n",
    "                    [\"Energy\"],\n",
    "                \"Total Waste\":\n",
    "                    [\"Waste\"],\n",
    "                \"Women Executives %\":\n",
    "                    [\"Women\", \"Female\"],\n",
    "                \"Women Board Members %\":\n",
    "                    [\"Women\", \"Female\"],\n",
    "                \"Total Board Members\":\n",
    "                    [\"Board Members?\"],\n",
    "                \"Independent Board Members %\":\n",
    "                    [\"Board Members?\"],\n",
    "                \"Audit Committee Independence %\":\n",
    "                    [\"Committee Independence\"],\n",
    "                \"Compensation Committee Independence %\":\n",
    "                    [\"Committee Independence\"],\n",
    "                \"Nomination Committee Independence %\":\n",
    "                    [\"Committee Independence\"],\n",
    "                \"ESG Sustainability Reporting\":\n",
    "                    [\"Sustainability Reporting\", \"ESG reporting\"],\n",
    "                \"Lost Time Injury Rate - Employees\":\n",
    "                    [\"Injury\", \"Emlployees?\"],\n",
    "                \"Avg Training Hours / Employee\":\n",
    "                    [\"Training Hours?\", \"Employee\"],\n",
    "                \"Trade Union Percentage\":\n",
    "                    [\"Trade Union\"],\n",
    "                \"CEO Salary / Average Salary\":\n",
    "                    [\"Salary\", \"CEO Salary\", \"Average Salary\"],\n",
    "                \"Employee Turnover %\":\n",
    "                    [\"Employee\", \"Turnover\"],\n",
    "                \"Involuntary Employee Turnover Rate\":\n",
    "                    [\"Employee\", \"Turnover\"],\n",
    "                \"Women's / Men's Compensation %\":\n",
    "                    [\"Women\", \"Female\", \"Men\", \"Male\"],\n",
    "                \"Women Employees %\":\n",
    "                    [\"Women\", \"Female\", \"Employees?\"],\n",
    "                \"Women Managers %\":\n",
    "                    [\"Women\", \"Female\", \"Managers?\"],\n",
    "                \"Minority Employees %\":\n",
    "                    [\"Minority\", \"Employees?\"]\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_metric= {\n",
    "#                 \"Emissions\":\n",
    "#                     [\"emission\", \"co2 emission\", \"ghg emission\", \"emission reduction\", \"emission target\", \"Emissions Policy\"],\n",
    "#                 \"Water\":\n",
    "#                     [\"Water Withdrawal\", \"Water Discharged\", \"Water Recycled\", \"water risk\"],\n",
    "#                 \"Energy\":\n",
    "#                     [\"Energy Consumed\", \"Renewable Energy\"],\n",
    "#                 \"Business Ethics\":\n",
    "#                     [\"Women Executives\", \"Women Board Members\", \"Board Members\", \"Committee Independence\", \"ESG Sustainability Reporting\"],\n",
    "#                 \"Labor Practices\":\n",
    "#                     [\"Trade Union\", \"CEO Salary\", \"Average Salary\", \"Employee Turnover\", \"Avg Training Hours\"],\n",
    "#                 \"Employee Engagement, Diversity & Inclusion\":\n",
    "#                     [\"Women Employees\", \"Women Managers\", \"Minority Employees\"],\n",
    "#                 \"Employee Health & Safety\":\n",
    "#                     [\"Lost Time\", \"Injury Rate\"],\n",
    "#                 \"Waste\":\n",
    "#                     [\"Waste\"]\n",
    "#                 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import camelot\n",
    "import os\n",
    "\n",
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i : i + n]\n",
    "def get_chunks(filepath, pages, chunk=10):\n",
    "    \"\"\"\n",
    "    Divide the extraction work into n chunks and return this chunks.\n",
    "\n",
    "    filepath : str\n",
    "        Filepath or URL of the PDF file.\n",
    "    pages : str, optional (default: '1')\n",
    "        Comma-separated page numbers.\n",
    "        Example: '1,3,4' or '1,4-end' or 'all'.\n",
    "    \"\"\"\n",
    "\n",
    "    # get list of pages from camelot.handlers.PDFHandler\n",
    "    handler = camelot.handlers.PDFHandler(filepath)\n",
    "    page_list = handler._get_pages(pages=pages)\n",
    "    # chunk pages list\n",
    "    page_chunks = list(chunks(page_list, chunk))\n",
    "\n",
    "    return page_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_information_table(tables):\n",
    "    for table in tables:\n",
    "        # print(table.cols)\n",
    "        # print(table.rows)\n",
    "        # print(tabel.accuracy)\n",
    "        table_df = table.df\n",
    "        columns = table_df.shape[1]\n",
    "        for key_word,value_words  in output_metric.items():\n",
    "            for col in range(columns):\n",
    "                contains = any(table.df[col].str.contains(\"|\".join(value_words), case=False, regex=True).tolist())\n",
    "                if contains:\n",
    "                    position_record_table[key_word].append(str(table.page))\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseTable_camelot(input_path, file, output_path, pages = \"all\"):\n",
    "    print(\"parsing table from \" + file + \" at \"+ pages + \" pages \" )\n",
    "    try:\n",
    "        filepath = os.path.join(input_path, file)\n",
    "        page_chunks = get_chunks(filepath, pages=pages)\n",
    "        for chunk in page_chunks:\n",
    "            pages_string = str(chunk).replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "            tables = camelot.read_pdf(filepath, pages=pages_string)\n",
    "            if len(tables) > 0:\n",
    "                check_information_table(tables)\n",
    "                # print(\"saving {len(tables)} tables\")\n",
    "                # accuracy = [str(table.parsing_report[\"accuracy\"]) for table in tables]\n",
    "                # print(\"accuracy list \" + \" \".join(accuracy))\n",
    "                # tables.export(os.path.join(output_path, file.replace(\"pdf\", \"xlsx\")), f='excel')\n",
    "            else:\n",
    "                print(f\"no tables found for \" + file)\n",
    "    except Exception as e:\n",
    "        print(\"error parsing table from \" + file)    \n",
    "        print(e)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tabula\n",
    "import pandas as pd\n",
    "def parseTable_tabula(input_path, file, output_path, pages):\n",
    "    print(\"parsing table from \" + file + \"at pages\" + pages)\n",
    "    try:\n",
    "        tables = tabula.read_pdf(os.path.join(input_path, file), pages=pages, lattice=True)\n",
    "        if len(tables) > 0:\n",
    "            print(\"saving {len(tables)} tables\")\n",
    "            with pd.ExcelWriter(os.path.join(output_path, file.replace(\"pdf\", \"xlsx\"))) as f_obj:\n",
    "                for i,table in enumerate(tables):\n",
    "                    table.to_excel(f_obj, sheet_name=str(i))\n",
    "        else:\n",
    "            print(f\"no tables found for \" + file)\n",
    "    except Exception as e:\n",
    "        print(\"error parsing table from \" + file)    \n",
    "        print(e) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def check_information_text(page, text):\n",
    "    for key_word, value_word in output_metric.items():\n",
    "        pattern = \"|\".join(value_word)\n",
    "        rex = re.search(pattern, text, re.I)\n",
    "        if rex != None:\n",
    "            position_record_text[key_word].append(str(page))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "def parseText(input_path, file, output_path, pages):\n",
    "    print(\"parsing text from \" + file + \" at \" + pages + \" pages \")\n",
    "    object = PyPDF2.PdfFileReader(os.path.join(input_path, file))\n",
    "    num_pages = object.getNumPages()\n",
    "    for i in range(0, num_pages):\n",
    "        page = object.getPage(i)\n",
    "        text = page.extractText()\n",
    "        text = text.replace('\\n','')\n",
    "        check_information_text(i, text)\n",
    "        # with open(os.path.join(output_path, file.replace(\"pdf\", \"text\")), \"a\") as f_obj:\n",
    "        #     f_obj.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import math\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(text):\n",
    "    lower = text.lower()\n",
    "    remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "    no_punctuation = lower.translate(remove_punctuation_map)\n",
    "    tokens = nltk.word_tokenize(no_punctuation)\n",
    "    return tokens\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(word, count):\n",
    "    return count[word] / sum(count.values())\n",
    "def n_containing(word, count_list):\n",
    "    return sum(1 for count in count_list if word in count)\n",
    "def idf(word, count_list):\n",
    "    return math.log(len(count_list)) / (1 + n_containing(word, count_list))\n",
    "def tfidf(word, count, count_list):\n",
    "    return tf(word, count) * idf(word, count_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_term(text):\n",
    "    tokens = get_tokens(text)\n",
    "    filtered = [w for w in tokens if not w in stopwords.words('english')]\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed = stem_tokens(filtered, stemmer)\n",
    "    count = Counter(stemmed)\n",
    "    return count\n",
    "\n",
    "def cal_tfidf(text_list, key_words):\n",
    "    countlist = []\n",
    "    for text in text_list:\n",
    "        countlist.append(count_term(text))\n",
    "    for i, count in enumerate(countlist):\n",
    "        print(\"Top words in document {}\".format(i + 1))\n",
    "        scores = {word: tfidf(word, count, countlist) for word in count}\n",
    "        sorted_words = sorted(scores.items(), key = lambda x: x[1], reverse=True)\n",
    "        for word, score in sorted_words[:5]:\n",
    "            print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing table from 2021-tesla-impact-report.pdf at pages all\n",
      "check the information\n",
      "check the information\n",
      "check the information\n",
      "check the information\n",
      "no tables found for 2021-tesla-impact-report.pdf\n",
      "check the information\n",
      "check the information\n",
      "check the information\n",
      "check the information\n",
      "check the information\n",
      "check the information\n",
      "check the information\n",
      "check the information\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/camelotenv/lib/python3.10/site-packages/camelot/parsers/lattice.py:411: UserWarning: page-138 is image-based, camelot only works on text-based pages.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check the information\n",
      "no tables found for 2021-tesla-impact-report.pdf\n",
      "parsing text from 2021-tesla-impact-report.pdf at pages all\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "input_path = \"./pdf_files\"\n",
    "output_table_camelot = \"./table_files_camelot\"\n",
    "output_table_tabula = \"./table_files_tabula\"\n",
    "output_path_text = \"./text_files\"\n",
    "pdf_files = os.listdir(input_path)\n",
    "name = [\"output_metric\", \"page\"]\n",
    "for file in pdf_files:\n",
    "    # 1 parsing the table and text\n",
    "    position_record_table = {key_word:[] for key_word in output_metric.keys()}\n",
    "    position_record_text = {key_word:[] for key_word in output_metric.keys()}\n",
    "    parseTable_camelot(input_path, file, output_table_camelot, pages=\"all\")\n",
    "    # parseTable_tabula(input_path, file, output_table_tabula)\n",
    "    parseText(input_path, file, output_path_text, \"all\")\n",
    "    # 2 save the result\n",
    "    position_record = {key_word:position_record_table[key_word]+position_record_text[key_word] \n",
    "                       for key_word in output_metric.keys()}\n",
    "    position_record = {key_word:list(set(pages)) for key_word, pages in position_record.items()}\n",
    "    position_matchs = [[key, \" \".join(value)] for key, value in position_record.items()]\n",
    "    data = pd.DataFrame(columns=name, data=position_matchs)\n",
    "    data.to_csv(\"./data_extraction/\" + file.replace(\".pdf\", \"_hybird.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('camelotenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0223c632f617fca949c57c3ca0f5d1cb8bdc1aa423ed0406ba10b84d4d8863b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
